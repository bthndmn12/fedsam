

Stratejiler, yinelemeli model eğitim süreci sırasında yerel güncellemelerin nasıl birleştirileceğini ve yönetileceğini düzenleyen kuralları tanımlar. Ayrıca, iletişim kısıtlamalarıyla başa çıkmak, aykırı katılımcıların etkilerini azaltmak ve model yakınsama oranlarını iyileştirmek için mekanizmalar içerebilirler. Araştırmalar, destekli öğrenme ve hibrit federe ikili koordinat yükselişi de dahil olmak üzere, federe öğrenmede yeni zorlukları ve senaryoları ele almak için mevcut stratejileri genişletmeye ve mevcut stratejileri geliştirmeye odaklanmaya devam etmektedir. 

Flower popüler hazır federe öğrenme stratejileri ile birlikte gelmektedir. 


Related work FEDAVG was first introduced by McMahan et al. (2017), who showed it can dramatically reduce communication costs. Many variants have since been proposed to tackle issues such as convergence and client drift. Examples include adding a regularization term in the client objectives towards the broadcast model (Li et al., 2018), and server momentum (Hsu et al., 2019). When clients are homogeneous, FEDAVG reduces to local SGD (Zinkevich et al., 2010), which has been analyzed by many works (Stich, 2019; Yu et al., 2019; Wang & Joshi, 2018; Stich & Karimireddy, 2019; Basu et al., 2019). In order to analyze FEDAVG in heterogeneous settings, many works derive convergence rates depending on the amount of heterogeneity (Li et al., 2018; Wang et al., 2019; Khaled et al., 2019; Li et al., 2019b). Typically, the convergence rate of FEDAVG gets worse with client heterogeneity. By using control variates to reduce client drift, the SCAFFOLD method (Karimireddy et al., 2019) achieves convergence rates that are independent of the amount of heterogeneity. While effective in cross-silo FL, the method is incompatible with cross-device FL as it requires clients to maintain state across rounds. For more detailed comparisons, we defer to Kairouz et al. (2019).
___
In medical image analysis, Federated Learning (FL) stands out as a key technology that enables privacy-preserved, decentralized data processing, crucial for handling sensitive medical data. Currently, most FL models employ random initialization, which has been proven effective in various instances. However, given the unique challenges posed by nonIID (independently and identically distributed) data in FL, we propose a novel perspective: exploring the impact of using the foundation model with enormous pre-trained knowledge, such as the Segment Anything Model (SAM), as an instructive teacher for FL model initialization in medical image segmentation task. This work for the first time attempts to utilize the foundation model as an instructive teacher for initialization in FL, assessing its impact on the performance of FL models, especially in non-IID data scenarios. Our empirical evaluation on chest x-ray lung segmentation showcases that FL with foundation model instructed initialization not only achieves faster convergence but also improves performance in complex data contexts. These findings offer a new perspective for model initialization in FL.

